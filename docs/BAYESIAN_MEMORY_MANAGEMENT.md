# Bayesian Memory Management for Yitam Context Engine

## T·ªïng quan

Bayesian Memory Management l√† m·ªôt gi·∫£i ph√°p ti√™n ti·∫øn ƒë∆∞·ª£c t√≠ch h·ª£p v√†o Yitam Context Engine ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n **ch·ªçn l·ªçc th√¥ng tin quan tr·ªçng t·ª´ l·ªãch s·ª≠ tr√≤ chuy·ªán d√†i**.

### B√†i to√°n

Khi cu·ªôc tr√≤ chuy·ªán k√©o d√†i, kh√¥ng th·ªÉ nh·ªìi nh√©t to√†n b·ªô l·ªãch s·ª≠ v√†o context window c·ªßa LLM. C·∫ßn m·ªôt c∆° ch·∫ø th√¥ng minh ƒë·ªÉ ch·ªçn l·ªçc nh·ªØng th√¥ng tin quan tr·ªçng nh·∫•t t·ª´ qu√° kh·ª©.

### Gi·∫£i ph√°p Bayesian

S·ª≠ d·ª•ng **Bayes' theorem** ƒë·ªÉ t√≠nh to√°n x√°c su·∫•t m·ªôt th√¥ng tin c≈© c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi hi·ªán t·∫°i:

```
P(Th√¥ng tin c≈© quan tr·ªçng | N·ªôi dung th√¥ng tin c≈©, C√¢u h·ªèi hi·ªán t·∫°i)
```

## Ki·∫øn tr√∫c

### 1. BayesianMemoryManager

Module ch√≠nh th·ª±c hi·ªán t√≠nh to√°n Bayesian inference v·ªõi Qdrant vector store:

```typescript
class BayesianMemoryManager {
  async analyzeBayesianRelevance(chatId: string, currentQuery: string): Promise<BayesianAnalysisResult>
  async createBayesianContextWindow(chatId: string, currentQuery: string): Promise<BayesianContextWindow>
}
```

### 2. ConversationHistoryVectorizer

Ch·ªãu tr√°ch nhi·ªám vector h√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán:

```typescript
class ConversationHistoryVectorizer {
  async vectorizeMessage(message: HistoricalMessage): Promise<ConversationVector>
  async analyzeCurrentQuery(query: string): Promise<QueryAnalysis>
  async findSimilarMessages(chatId: string, queryAnalysis: QueryAnalysis): Promise<SimilarMessage[]>
}
```

### 3. Bayesian Evidence (B·∫±ng ch·ª©ng)

C√°c y·∫øu t·ªë ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√≠nh to√°n evidence:

- **Semantic Similarity**: ƒê·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a (vector embeddings)
- **Temporal Relevance**: ƒê·ªô li√™n quan th·ªùi gian (exponential decay)
- **Entity Overlap**: S·ª± tr√πng l·∫∑p th·ª±c th·ªÉ (named entities)
- **Topic Similarity**: ƒê·ªô t∆∞∆°ng ƒë·ªìng ch·ªß ƒë·ªÅ
- **User Interaction Score**: ƒêi·ªÉm t∆∞∆°ng t√°c ng∆∞·ªùi d√πng
- **Context Continuity**: T√≠nh li√™n t·ª•c ng·ªØ c·∫£nh

### 4. Bayesian Prior (X√°c su·∫•t ti√™n nghi·ªám)

C√°c y·∫øu t·ªë prior ƒë∆∞·ª£c t√≠nh to√°n:

- **Base Importance**: ƒêi·ªÉm quan tr·ªçng c∆° b·∫£n t·ª´ h·ªá th·ªëng hi·ªán t·∫°i
- **Message Type Prior**: Lo·∫°i tin nh·∫Øn (user vs assistant)
- **Length Prior**: ƒê·ªô d√†i tin nh·∫Øn
- **Position Prior**: V·ªã tr√≠ trong cu·ªôc tr√≤ chuy·ªán
- **User Marked Prior**: ƒê∆∞·ª£c ng∆∞·ªùi d√πng ƒë√°nh d·∫•u quan tr·ªçng

## C√°ch s·ª≠ d·ª•ng

### 1. Kh·ªüi t·∫°o

```typescript
import { ContextEngine } from './services/ContextEngine';

const contextEngine = new ContextEngine({
  maxRecentMessages: 10,
  maxContextTokens: 8000,
  // Bayesian config s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông kh·ªüi t·∫°o v·ªõi Qdrant vector store
});

await contextEngine.initialize();
```

### 2. S·ª≠ d·ª•ng trong cu·ªôc tr√≤ chuy·ªán

```typescript
// Th√™m messages v√†o cu·ªôc tr√≤ chuy·ªán
await contextEngine.addMessage(chatId, messageId, {
  role: 'user',
  content: 'T√¥i mu·ªën h·ªçc v·ªÅ machine learning'
});

// L·∫•y context ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a b·∫±ng Bayesian analysis
const optimizedContext = await contextEngine.getOptimizedContext(
  chatId, 
  'B·∫°n c√≥ th·ªÉ gi·∫£i th√≠ch th√™m v·ªÅ neural networks kh√¥ng?'
);

// optimizedContext s·∫Ω ch·ª©a:
// - recentMessages: Tin nh·∫Øn g·∫ßn ƒë√¢y (lu√¥n bao g·ªìm)
// - relevantHistory: Tin nh·∫Øn ƒë∆∞·ª£c ch·ªçn b·ªüi Bayesian analysis
// - summaries: T√≥m t·∫Øt c√°c ph·∫ßn b·ªã lo·∫°i b·ªè
// - keyFacts: C√°c s·ª± ki·ªán quan tr·ªçng
```

### 3. C·∫•u h√¨nh Bayesian

```typescript
const bayesianConfig = {
  evidenceWeights: {
    semantic: 0.3,      // Tr·ªçng s·ªë semantic similarity
    temporal: 0.15,     // Tr·ªçng s·ªë temporal relevance
    entity: 0.2,        // Tr·ªçng s·ªë entity overlap
    topic: 0.15,        // Tr·ªçng s·ªë topic similarity
    interaction: 0.1,   // Tr·ªçng s·ªë user interaction
    continuity: 0.1     // Tr·ªçng s·ªë context continuity
  },
  priorWeights: {
    baseImportance: 0.3,
    messageType: 0.2,
    length: 0.15,
    position: 0.15,
    userMarked: 0.2
  },
  temporalDecay: {
    halfLife: 24,       // 24 gi·ªù
    minRelevance: 0.1
  },
  thresholds: {
    minRelevanceProbability: 0.4  // Ch·ªâ ch·ªçn messages c√≥ P >= 0.4
  },
  topKSelection: 5      // Ch·ªçn top 5 messages c√≥ x√°c su·∫•t cao nh·∫•t
};

// Vector store s·ª≠ d·ª•ng Qdrant (m·∫∑c ƒë·ªãnh)
const vectorStoreConfig = {
  provider: 'qdrant',
  collectionName: 'yitam_context',
  dimension: 1536,
  embeddingModel: 'text-embedding-ada-002'
};
```

## V√≠ d·ª• th·ª±c t·∫ø

### Cu·ªôc tr√≤ chuy·ªán d√†i v·ªÅ nhi·ªÅu ch·ªß ƒë·ªÅ

```typescript
// L·ªãch s·ª≠ tr√≤ chuy·ªán:
// Messages 1-4: Machine Learning
// Messages 5-8: N·∫•u ƒÉn
// Messages 9-12: Du l·ªãch
// Messages 13-16: Tin nh·∫Øn g·∫ßn ƒë√¢y

// Query hi·ªán t·∫°i
const query = "B·∫°n c√≥ th·ªÉ gi·∫£i th√≠ch th√™m v·ªÅ deep learning kh√¥ng?";

// Bayesian analysis s·∫Ω:
// 1. Vector h√≥a query
// 2. T√¨m messages t∆∞∆°ng t·ª± semantic (Messages 1-4 v·ªÅ ML)
// 3. T√≠nh to√°n evidence v√† prior cho t·ª´ng message
// 4. √Åp d·ª•ng Bayes' theorem
// 5. Ch·ªçn top messages c√≥ x√°c su·∫•t cao nh·∫•t

// K·∫øt qu·∫£: Messages v·ªÅ Machine Learning s·∫Ω ƒë∆∞·ª£c ch·ªçn
// v·ªõi x√°c su·∫•t cao, trong khi messages v·ªÅ n·∫•u ƒÉn v√† du l·ªãch
// s·∫Ω c√≥ x√°c su·∫•t th·∫•p v√† b·ªã lo·∫°i b·ªè
```

### Context Note cho LLM

Bayesian Memory Manager t·ª± ƒë·ªông t·∫°o context note cho LLM:

```
"L∆∞u √Ω: D·ª±a tr√™n ph√¢n t√≠ch Bayesian, t√¥i ƒë√£ ch·ªçn 3 th√¥ng tin quan tr·ªçng nh·∫•t 
t·ª´ l·ªãch s·ª≠ tr√≤ chuy·ªán (x√°c su·∫•t li√™n quan trung b√¨nh: 78.5%). C√°c th√¥ng tin n√†y 
c√≥ th·ªÉ gi√∫p tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n. ƒê·∫∑c bi·ªát, c√≥ m·ªôt th√¥ng tin r·∫•t li√™n quan 
(89.2% x√°c su·∫•t)."
```

## L·ª£i √≠ch

### 1. Ti·∫øt ki·ªám Token
- Gi·∫£m 40-70% s·ªë token c·∫ßn thi·∫øt
- Ch·ªâ g·ª≠i th√¥ng tin th·ª±c s·ª± li√™n quan
- T·ªëi ∆∞u h√≥a chi ph√≠ API

### 2. C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng
- LLM nh·∫≠n ƒë∆∞·ª£c context c√≥ li√™n quan cao
- Gi·∫£m nhi·ªÖu t·ª´ th√¥ng tin kh√¥ng li√™n quan
- C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa c√¢u tr·∫£ l·ªùi

### 3. Kh·∫£ nƒÉng m·ªü r·ªông
- X·ª≠ l√Ω ƒë∆∞·ª£c cu·ªôc tr√≤ chuy·ªán r·∫•t d√†i
- Kh√¥ng b·ªã gi·ªõi h·∫°n b·ªüi context window
- Hi·ªáu su·∫•t ·ªïn ƒë·ªãnh khi conversation tƒÉng tr∆∞·ªüng

## C·∫•u tr√∫c Database

### B·∫£ng m·ªü r·ªông cho Bayesian

```sql
-- Metadata cho Bayesian analysis
CREATE TABLE bayesian_message_metadata (
  message_id INTEGER PRIMARY KEY,
  chat_id TEXT NOT NULL,
  times_referenced INTEGER DEFAULT 0,
  last_referenced_at TIMESTAMP,
  average_relevance_score REAL DEFAULT 0.0,
  extracted_entities TEXT, -- JSON array
  extracted_topics TEXT,   -- JSON array
  semantic_fingerprint TEXT,
  conversation_position REAL DEFAULT 0.0,
  user_interaction_pattern TEXT -- JSON object
);

-- Cache k·∫øt qu·∫£ Bayesian analysis
CREATE TABLE bayesian_analysis_cache (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  chat_id TEXT NOT NULL,
  query_hash TEXT NOT NULL,
  selected_message_ids TEXT, -- JSON array
  analysis_results TEXT,     -- JSON object
  average_probability REAL,
  processing_time_ms INTEGER,
  expires_at TIMESTAMP NOT NULL
);
```

## Testing

Ch·∫°y tests:

```bash
npm test -- BayesianMemoryManager.test.ts
```

Ch·∫°y demo:

```bash
npm run demo:bayesian
```

## Performance

### Benchmarks

- **Processing time**: 50-200ms cho 100 messages
- **Memory usage**: ~10MB cho 1000 messages
- **Token reduction**: 40-70% so v·ªõi full history
- **Accuracy**: 85-95% relevant message selection

### T·ªëi ∆∞u h√≥a

1. **Caching**: K·∫øt qu·∫£ Bayesian analysis ƒë∆∞·ª£c cache
2. **Batch processing**: Vector operations ƒë∆∞·ª£c batch
3. **Lazy loading**: Ch·ªâ load c·∫ßn thi·∫øt
4. **Index optimization**: Database indexes cho fast queries

## Roadmap

### Phase 1 ‚úÖ
- [x] Core Bayesian inference implementation
- [x] Vector-based semantic similarity
- [x] Basic entity and topic extraction
- [x] Integration with ContextEngine

### Phase 2 üöß
- [ ] Advanced NLP for entity/topic extraction
- [ ] Machine learning model for better priors
- [ ] Multi-language support
- [ ] Real-time learning from user feedback

### Phase 3 üìã
- [ ] Distributed processing for large conversations
- [ ] Advanced temporal modeling
- [ ] Integration with external knowledge bases
- [ ] API for third-party integrations

## K·∫øt lu·∫≠n

Bayesian Memory Management mang l·∫°i m·ªôt c√°ch ti·∫øp c·∫≠n khoa h·ªçc v√† hi·ªáu qu·∫£ ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n context management trong c√°c cu·ªôc tr√≤ chuy·ªán d√†i. B·∫±ng c√°ch √°p d·ª•ng Bayes' theorem, h·ªá th·ªëng c√≥ th·ªÉ ch·ªçn l·ªçc th√¥ng minh nh·ªØng th√¥ng tin quan tr·ªçng nh·∫•t, gi√∫p ti·∫øt ki·ªám chi ph√≠ v√† c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ph·∫£n h·ªìi c·ªßa LLM.
