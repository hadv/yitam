# Server Configuration
PORT=5001
CLIENT_URL=http://localhost:3000

# LLM Provider Configuration
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-7-sonnet-20250219
LLM_MAX_TOKENS=10000
LLM_TEMPERATURE=0.7
LLM_TOP_P=1.0

# LLM Fallback Configuration
LLM_FALLBACK_ENABLED=true
LLM_FALLBACK_PROVIDERS=anthropic,openai

# API Keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Legacy Anthropic Config (for backward compatibility)uration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-7-sonnet-20250219
MODEL_MAX_TOKENS=1000

# MCP Configuration
MCP_SERVER_PATH=path/to/your/mcp_server.js

# Add other environment variables here 