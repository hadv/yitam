/**
 * Example demonstrating Bayesian Memory Management in Yitam Context Engine
 */

import { ContextEngine } from '../services/ContextEngine';
import { BayesianMemoryManager } from '../services/BayesianMemoryManager';
import { VectorStoreManager } from '../services/VectorStore';
import { HistoricalMessage } from '../types/BayesianTypes';

export class BayesianMemoryExample {
  private contextEngine: ContextEngine;
  private bayesianManager?: BayesianMemoryManager;
  private vectorStore?: VectorStoreManager;

  constructor() {
    // Initialize Context Engine with Bayesian support
    this.contextEngine = new ContextEngine({
      maxRecentMessages: 10,
      maxContextTokens: 8000
    });
  }

  async initialize(): Promise<void> {
    await this.contextEngine.initialize();
    console.log('‚úÖ Bayesian Memory Management initialized');
  }

  /**
   * Demo: Cu·ªôc tr√≤ chuy·ªán d√†i v·ªÅ nhi·ªÅu ch·ªß ƒë·ªÅ
   */
  async demonstrateLongConversation(): Promise<void> {
    console.log('\nüéØ Demo: Cu·ªôc tr√≤ chuy·ªán d√†i v·ªõi nhi·ªÅu ch·ªß ƒë·ªÅ\n');

    const chatId = 'demo-long-conversation';
    await this.contextEngine.createConversation(chatId, 'demo-user', 'Long Conversation Demo');

    // Simulate a long conversation with multiple topics
    const conversationHistory = [
      // Topic 1: Machine Learning (messages 1-4)
      { id: 1, role: 'user', content: 'T√¥i mu·ªën h·ªçc v·ªÅ machine learning. B·∫°n c√≥ th·ªÉ gi√∫p t√¥i kh√¥ng?', timestamp: new Date('2024-01-01T09:00:00Z') },
      { id: 2, role: 'assistant', content: 'T·∫•t nhi√™n! Machine learning l√† m·ªôt nh√°nh c·ªßa AI. B·∫°n mu·ªën b·∫Øt ƒë·∫ßu t·ª´ ƒë√¢u?', timestamp: new Date('2024-01-01T09:01:00Z') },
      { id: 3, role: 'user', content: 'T√¥i quan t√¢m ƒë·∫øn neural networks v√† deep learning', timestamp: new Date('2024-01-01T09:02:00Z') },
      { id: 4, role: 'assistant', content: 'Neural networks l√† n·ªÅn t·∫£ng c·ªßa deep learning. Ch√∫ng ta c√≥ th·ªÉ b·∫Øt ƒë·∫ßu v·ªõi perceptron ƒë∆°n gi·∫£n.', timestamp: new Date('2024-01-01T09:03:00Z') },

      // Topic 2: Cooking (messages 5-8)
      { id: 5, role: 'user', content: 'Chuy·ªÉn ch·ªß ƒë·ªÅ nh√©. B·∫°n c√≥ bi·∫øt c√°ch n·∫•u ph·ªü kh√¥ng?', timestamp: new Date('2024-01-01T10:00:00Z') },
      { id: 6, role: 'assistant', content: 'Ph·ªü l√† m√≥n ƒÉn truy·ªÅn th·ªëng Vi·ªát Nam. C·∫ßn n∆∞·ªõc d√πng trong, b√°nh ph·ªü v√† th·ªãt b√≤.', timestamp: new Date('2024-01-01T10:01:00Z') },
      { id: 7, role: 'user', content: 'L√†m th·∫ø n√†o ƒë·ªÉ n∆∞·ªõc d√πng ph·ªü trong v√† ng·ªçt?', timestamp: new Date('2024-01-01T10:02:00Z') },
      { id: 8, role: 'assistant', content: 'B√≠ quy·∫øt l√† ninh x∆∞∆°ng b√≤ l√¢u, th√™m h√†nh t√¢y n∆∞·ªõng v√† gia v·ªã ƒë·∫∑c bi·ªát.', timestamp: new Date('2024-01-01T10:03:00Z') },

      // Topic 3: Travel (messages 9-12)
      { id: 9, role: 'user', content: 'T√¥i ƒëang l√™n k·∫ø ho·∫°ch du l·ªãch ƒê√† L·∫°t. C√≥ g·ª£i √Ω g√¨ kh√¥ng?', timestamp: new Date('2024-01-01T11:00:00Z') },
      { id: 10, role: 'assistant', content: 'ƒê√† L·∫°t r·∫•t ƒë·∫πp! B·∫°n n√™n thƒÉm H·ªì Xu√¢n H∆∞∆°ng, ch·ª£ ƒë√™m v√† c√°c v∆∞·ªùn hoa.', timestamp: new Date('2024-01-01T11:01:00Z') },
      { id: 11, role: 'user', content: 'Th·ªùi ti·∫øt ·ªü ƒê√† L·∫°t nh∆∞ th·∫ø n√†o v√†o m√πa n√†y?', timestamp: new Date('2024-01-01T11:02:00Z') },
      { id: 12, role: 'assistant', content: 'ƒê√† L·∫°t m√°t m·∫ª quanh nƒÉm, nhi·ªát ƒë·ªô kho·∫£ng 15-25¬∞C. N√™n mang √°o ·∫•m.', timestamp: new Date('2024-01-01T11:03:00Z') },

      // Recent messages (13-16)
      { id: 13, role: 'user', content: 'C·∫£m ∆°n b·∫°n v·ªÅ th√¥ng tin du l·ªãch!', timestamp: new Date('2024-01-01T12:00:00Z') },
      { id: 14, role: 'assistant', content: 'Kh√¥ng c√≥ g√¨! T√¥i lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª°.', timestamp: new Date('2024-01-01T12:01:00Z') },
      { id: 15, role: 'user', content: 'B√¢y gi·ªù t√¥i mu·ªën quay l·∫°i ch·ªß ƒë·ªÅ machine learning', timestamp: new Date('2024-01-01T12:02:00Z') },
      { id: 16, role: 'assistant', content: 'Tuy·ªát! Ch√∫ng ta ƒë√£ n√≥i v·ªÅ neural networks. B·∫°n mu·ªën t√¨m hi·ªÉu s√¢u h∆°n v·ªÅ g√¨?', timestamp: new Date('2024-01-01T12:03:00Z') }
    ];

    // Add all messages to context engine
    for (const msg of conversationHistory) {
      await this.contextEngine.addMessage(chatId, msg.id, {
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      });
    }

    console.log(`üìù ƒê√£ th√™m ${conversationHistory.length} messages v√†o cu·ªôc tr√≤ chuy·ªán`);

    // Now test Bayesian memory with different queries
    await this.testBayesianQueries(chatId);
  }

  /**
   * Test Bayesian memory v·ªõi c√°c c√¢u h·ªèi kh√°c nhau
   */
  private async testBayesianQueries(chatId: string): Promise<void> {
    const testQueries = [
      {
        query: 'B·∫°n c√≥ th·ªÉ gi·∫£i th√≠ch th√™m v·ªÅ deep learning kh√¥ng?',
        expectedTopic: 'Machine Learning',
        description: 'Query v·ªÅ ML - should retrieve ML-related messages'
      },
      {
        query: 'L√†m sao ƒë·ªÉ n·∫•u m·ªôt n·ªìi ph·ªü ngon?',
        expectedTopic: 'Cooking',
        description: 'Query v·ªÅ n·∫•u ƒÉn - should retrieve cooking messages'
      },
      {
        query: 'T√¥i n√™n mang g√¨ khi ƒëi ƒê√† L·∫°t?',
        expectedTopic: 'Travel',
        description: 'Query v·ªÅ du l·ªãch - should retrieve travel messages'
      },
      {
        query: 'T√≥m t·∫Øt nh·ªØng g√¨ ch√∫ng ta ƒë√£ th·∫£o lu·∫≠n',
        expectedTopic: 'General',
        description: 'General query - should retrieve diverse messages'
      }
    ];

    for (const testCase of testQueries) {
      console.log(`\nüîç Testing query: "${testCase.query}"`);
      console.log(`üìã Expected topic: ${testCase.expectedTopic}`);
      console.log(`üí° Description: ${testCase.description}`);

      try {
        // Get optimized context using Bayesian analysis
        const optimizedContext = await this.contextEngine.getOptimizedContext(chatId, testCase.query);

        console.log(`\nüìä Bayesian Analysis Results:`);
        console.log(`   ‚Ä¢ Total tokens: ${optimizedContext.totalTokens}`);
        console.log(`   ‚Ä¢ Compression ratio: ${(optimizedContext.compressionRatio * 100).toFixed(1)}%`);
        console.log(`   ‚Ä¢ Recent messages: ${optimizedContext.recentMessages.length}`);
        console.log(`   ‚Ä¢ Relevant history: ${optimizedContext.relevantHistory.length}`);
        console.log(`   ‚Ä¢ Summaries: ${optimizedContext.summaries.length}`);
        console.log(`   ‚Ä¢ Key facts: ${optimizedContext.keyFacts.length}`);

        // Show selected messages (simplified)
        if (optimizedContext.relevantHistory.length > 0) {
          console.log(`\nüìã Selected relevant messages:`);
          optimizedContext.relevantHistory.forEach((msg, index) => {
            const preview = typeof msg.content === 'string' 
              ? msg.content.substring(0, 60) + '...'
              : JSON.stringify(msg.content).substring(0, 60) + '...';
            console.log(`   ${index + 1}. [${msg.role}] ${preview}`);
          });
        }

        // Simulate LLM response based on context
        const response = this.generateContextualResponse(testCase.query, optimizedContext);
        console.log(`\nü§ñ Contextual Response: ${response}`);

      } catch (error) {
        console.error(`‚ùå Error processing query: ${error}`);
      }

      console.log('\n' + '‚îÄ'.repeat(80));
    }
  }

  /**
   * Generate a contextual response based on optimized context
   */
  private generateContextualResponse(query: string, context: any): string {
    const lowerQuery = query.toLowerCase();

    if (lowerQuery.includes('deep learning') || lowerQuery.includes('machine learning')) {
      return "D·ª±a tr√™n cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc ƒë√≥ v·ªÅ machine learning, t√¥i c√≥ th·ªÉ gi·∫£i th√≠ch th√™m v·ªÅ deep learning v√† neural networks m√† ch√∫ng ta ƒë√£ th·∫£o lu·∫≠n...";
    }

    if (lowerQuery.includes('ph·ªü') || lowerQuery.includes('n·∫•u')) {
      return "Nh∆∞ t√¥i ƒë√£ chia s·∫ª tr∆∞·ªõc ƒë√≥ v·ªÅ c√°ch n·∫•u ph·ªü, b√≠ quy·∫øt quan tr·ªçng nh·∫•t l√† n∆∞·ªõc d√πng. ƒê·ªÉ b·ªï sung th√™m...";
    }

    if (lowerQuery.includes('ƒë√† l·∫°t') || lowerQuery.includes('du l·ªãch')) {
      return "V·ªÅ chuy·∫øn du l·ªãch ƒê√† L·∫°t m√† b·∫°n ƒëang l√™n k·∫ø ho·∫°ch, ngo√†i nh·ªØng g·ª£i √Ω v·ªÅ th·ªùi ti·∫øt v√† ƒë·ªãa ƒëi·ªÉm t√¥i ƒë√£ ƒë·ªÅ c·∫≠p...";
    }

    if (lowerQuery.includes('t√≥m t·∫Øt') || lowerQuery.includes('th·∫£o lu·∫≠n')) {
      return "Trong cu·ªôc tr√≤ chuy·ªán c·ªßa ch√∫ng ta, ch√∫ng ta ƒë√£ th·∫£o lu·∫≠n v·ªÅ 3 ch·ªß ƒë·ªÅ ch√≠nh: machine learning (neural networks), n·∫•u ƒÉn (ph·ªü), v√† du l·ªãch (ƒê√† L·∫°t)...";
    }

    return "D·ª±a tr√™n ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán, t√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi c√¢u h·ªèi n√†y...";
  }

  /**
   * Demo performance comparison
   */
  async demonstratePerformanceComparison(): Promise<void> {
    console.log('\n‚ö° Demo: So s√°nh hi·ªáu su·∫•t Bayesian vs Traditional\n');

    const chatId = 'performance-test';
    await this.contextEngine.createConversation(chatId, 'perf-user', 'Performance Test');

    // Create a large conversation history
    const largeHistory = this.generateLargeConversationHistory(100); // 100 messages

    console.log(`üìù T·∫°o cu·ªôc tr√≤ chuy·ªán v·ªõi ${largeHistory.length} messages...`);

    for (const msg of largeHistory) {
      await this.contextEngine.addMessage(chatId, msg.id, {
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      });
    }

    const testQuery = 'Tell me about the machine learning project we discussed';

    // Test Bayesian approach
    console.log('\nüß† Testing Bayesian Memory Management...');
    const bayesianStart = Date.now();
    const bayesianContext = await this.contextEngine.getOptimizedContext(chatId, testQuery);
    const bayesianTime = Date.now() - bayesianStart;

    // Test traditional approach (without query)
    console.log('üìö Testing Traditional Context Retrieval...');
    const traditionalStart = Date.now();
    const traditionalContext = await this.contextEngine.getOptimizedContext(chatId); // No query
    const traditionalTime = Date.now() - traditionalStart;

    // Compare results
    console.log('\nüìä Performance Comparison:');
    console.log(`   Bayesian Approach:`);
    console.log(`     ‚Ä¢ Processing time: ${bayesianTime}ms`);
    console.log(`     ‚Ä¢ Selected messages: ${bayesianContext.relevantHistory.length}`);
    console.log(`     ‚Ä¢ Total tokens: ${bayesianContext.totalTokens}`);
    console.log(`     ‚Ä¢ Compression ratio: ${(bayesianContext.compressionRatio * 100).toFixed(1)}%`);

    console.log(`   Traditional Approach:`);
    console.log(`     ‚Ä¢ Processing time: ${traditionalTime}ms`);
    console.log(`     ‚Ä¢ Selected messages: ${traditionalContext.relevantHistory.length}`);
    console.log(`     ‚Ä¢ Total tokens: ${traditionalContext.totalTokens}`);
    console.log(`     ‚Ä¢ Compression ratio: ${(traditionalContext.compressionRatio * 100).toFixed(1)}%`);

    const tokenSavings = traditionalContext.totalTokens - bayesianContext.totalTokens;
    const percentSavings = (tokenSavings / traditionalContext.totalTokens * 100).toFixed(1);

    console.log(`\nüí∞ Token Savings: ${tokenSavings} tokens (${percentSavings}%)`);
    console.log(`üéØ Relevance Improvement: Bayesian selection provides more contextually relevant messages`);
  }

  /**
   * Generate large conversation history for testing
   */
  private generateLargeConversationHistory(count: number): Array<{id: number, role: string, content: string, timestamp: Date}> {
    const topics = [
      { topic: 'machine learning', messages: [
        'What is machine learning?',
        'Machine learning is a subset of AI that enables computers to learn without explicit programming.',
        'Can you explain neural networks?',
        'Neural networks are computing systems inspired by biological neural networks.',
        'How do I start a machine learning project?',
        'Start by defining your problem, collecting data, and choosing appropriate algorithms.'
      ]},
      { topic: 'cooking', messages: [
        'How do I cook pasta?',
        'Boil water, add salt, cook pasta for 8-12 minutes until al dente.',
        'What ingredients do I need for pizza?',
        'You need flour, yeast, water, salt for dough, plus toppings like tomato sauce and cheese.',
        'How long should I bake a cake?',
        'Most cakes bake for 25-35 minutes at 350¬∞F, but check with a toothpick.'
      ]},
      { topic: 'travel', messages: [
        'Where should I visit in Vietnam?',
        'Vietnam has many beautiful places: Ha Long Bay, Hoi An, Ho Chi Minh City, and Sapa.',
        'What is the best time to visit Japan?',
        'Spring (March-May) and autumn (September-November) are ideal for visiting Japan.',
        'How do I plan a budget trip?',
        'Set a budget, book flights early, stay in hostels, eat local food, and use public transport.'
      ]}
    ];

    const history = [];
    const baseTime = new Date('2024-01-01T08:00:00Z');

    for (let i = 0; i < count; i++) {
      const topicIndex = i % topics.length;
      const messageIndex = Math.floor(i / topics.length) % topics[topicIndex].messages.length;
      const role = i % 2 === 0 ? 'user' : 'assistant';
      
      history.push({
        id: i + 1,
        role,
        content: topics[topicIndex].messages[messageIndex],
        timestamp: new Date(baseTime.getTime() + i * 60000) // 1 minute apart
      });
    }

    return history;
  }

  /**
   * Run the complete demo
   */
  async runDemo(): Promise<void> {
    try {
      await this.initialize();
      
      console.log('üöÄ Starting Bayesian Memory Management Demo\n');
      console.log('=' .repeat(80));
      
      await this.demonstrateLongConversation();
      
      console.log('\n' + '='.repeat(80));
      
      await this.demonstratePerformanceComparison();
      
      console.log('\n‚úÖ Demo completed successfully!');
      
    } catch (error) {
      console.error('‚ùå Demo failed:', error);
    } finally {
      await this.contextEngine.cleanup();
    }
  }
}

// Run demo if this file is executed directly
if (typeof require !== 'undefined' && require.main === module) {
  const demo = new BayesianMemoryExample();
  demo.runDemo().catch(console.error);
}
